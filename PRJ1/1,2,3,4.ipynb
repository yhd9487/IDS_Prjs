{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T05:19:39.446633300Z",
     "start_time": "2023-10-29T05:19:39.429637100Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 477\n",
      "Number of columns: 1097\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('movieReplicationSet.csv')\n",
    "num_rows = data.shape[1]\n",
    "num_columns = data.shape[0]\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T05:19:39.487630300Z",
     "start_time": "2023-10-29T05:19:39.443630300Z"
    }
   },
   "id": "730743eb62c40230"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# null value analyze\n",
    "null_counts_per_row = data.isnull().sum(axis=1)\n",
    "\n",
    "# Analyze and print the number of rows with greater than a specific number of null values\n",
    "thresholds = [100, 200, 300, 400]\n",
    "for threshold in thresholds:\n",
    "    count = len(null_counts_per_row[null_counts_per_row > threshold])\n",
    "    print(f\"Number of rows with more than {threshold} null values: {count}\")\n",
    "\n",
    "# Draw distribution chart\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.histplot(null_counts_per_row, kde=True, bins=100)\n",
    "plt.title('Distribution of Null Values Per Row')\n",
    "plt.xlabel('Number of Null Values')\n",
    "plt.ylabel('Number of Rows')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee9b2a683f4fe8bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) Are movies that are more popular (operationalized as having more ratings) rated higher than movies that are less popular? [Hint: You can do a median-split of popularity to determine high vs. low popularity movies] \n",
    "\n",
    "# First calculate the number of non-missing ratings and average rating for each movie\n",
    "movie_ratings = data.iloc[:, 0:400]\n",
    "movie_popularity = movie_ratings.count()\n",
    "movie_avg_ratings = movie_ratings.mean()\n",
    "\n",
    "# Then perform a median split based on popularity\n",
    "median_popularity = movie_popularity.median()\n",
    "high_popularity_movies = movie_avg_ratings[movie_popularity > median_popularity]\n",
    "median_popularity_movies = movie_avg_ratings[movie_popularity == median_popularity]\n",
    "low_popularity_movies = movie_avg_ratings[movie_popularity < median_popularity]\n",
    "\n",
    "# List the number of movies of each type\n",
    "number_of_high_popularity_movies = len(high_popularity_movies)\n",
    "number_of_median_popularity_movies = len(median_popularity_movies)\n",
    "number_of_low_popularity_movies = len(low_popularity_movies)\n",
    "\n",
    "print(\n",
    "    f\"Num of movie rate in high:{number_of_high_popularity_movies}\"\n",
    "    f\", median: {number_of_median_popularity_movies}\"\n",
    "    f\", low: {number_of_low_popularity_movies}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80da7cca98edd362"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normal distribution image test\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Histograms and Q-Q plots of high-rating movies\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(high_popularity_movies, bins=20, edgecolor='k')\n",
    "plt.title('Histogram of High Popularity Movies Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sm.qqplot(high_popularity_movies, line='45', fit=True)\n",
    "plt.title('Q-Q Plot of High Popularity Movies Ratings')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogram and Q-Q plot of low-rating movies\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(low_popularity_movies.dropna(), bins=20, edgecolor='k')\n",
    "plt.title('Histogram of Low Popularity Movies Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sm.qqplot(low_popularity_movies.dropna(), line='45', fit=True)\n",
    "plt.title('Q-Q Plot of Low Popularity Movies Ratings')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f81c1945e53259bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test whether the ratings of high-rated movies conform to the normal distribution\n",
    "from scipy.stats import kstest\n",
    "\n",
    "stat_high, p_high = kstest(high_popularity_movies, 'norm', args=(np.mean(high_popularity_movies), np.std(high_popularity_movies)))\n",
    "if p_high > 0.005:\n",
    "    print(\"High popularity movies' ratings appear to be normally distributed according to KS test.\")\n",
    "else:\n",
    "    print(\"High popularity movies' ratings do not appear to be normally distributed according to KS test.\")\n",
    "\n",
    "# Test whether the ratings of low-rated movies follow a normal distribution\n",
    "stat_low, p_low = kstest(low_popularity_movies.dropna(), 'norm', args=(np.mean(low_popularity_movies), np.std(low_popularity_movies)))\n",
    "if p_low > 0.005:\n",
    "    print(\"Low popularity movies' ratings appear to be normally distributed according to KS test.\")\n",
    "else:\n",
    "    print(\"Low popularity movies' ratings do not appear to be normally distributed according to KS test.\")\n",
    "\n",
    "print(\"KS test p-value for high popularity movies: \", p_high)\n",
    "print(\"KS test p-value for low popularity movies: \", p_low)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "220695bde97e8c51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Variance calculation\n",
    "variance_high = np.var(high_popularity_movies, ddof=1)\n",
    "variance_low = np.var(low_popularity_movies, ddof=1)\n",
    "\n",
    "print(\"高人气电影评分的样本方差:\", variance_high)\n",
    "print(\"低人气电影评分的样本方差:\", variance_low)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b784cc473465659"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Welch t-test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "t_statistic, p_value = ttest_ind(high_popularity_movies, low_popularity_movies, equal_var=False)\n",
    "\n",
    "print(f\"Welch's T-test p-value: {p_value}\")\n",
    "print(f\"Welch's T-test statistic: {t_statistic}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e9506f1845d3ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mann-whitney U test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "U, p_value = mannwhitneyu(high_popularity_movies, low_popularity_movies.dropna())\n",
    "\n",
    "print(f\"Mann-Whitney U test p-value: {p_value}\")\n",
    "print(f\"Mann-Whitney U test U value: {U}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45dbc1b2e992928c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39729c9f06b8b98f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) Are movies that are newer rated differently than movies that are older? [Hint: Do a median split of year of release to contrast movies in terms of whether they are old or new]\n",
    "\n",
    "# Extract the year from the movie title\n",
    "years = data.columns[0:400].str.extract(r'\\((\\d{4})\\)')[0].astype(int)\n",
    "\n",
    "# Calculate the average rating of each movie\n",
    "movie_ratings = data.iloc[:, 0:400]\n",
    "movie_avg_ratings = movie_ratings.mean()\n",
    "\n",
    "# Use the median of the years to divide movies into new and old movies\n",
    "median_year = years.median()\n",
    "new_movies = movie_avg_ratings[years.values > median_year]\n",
    "old_movies = movie_avg_ratings[years.values <= median_year]\n",
    "print(f\"median year:{median_year}\")\n",
    "print(f\"number of new movies:{len(new_movies)}\")\n",
    "print(f\"number of old movies:{len(old_movies)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba7a4e4f56d3a71e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normal distribution image test\n",
    "\n",
    "# Get all ratings for old and new movies\n",
    "ratings_new_movies = movie_ratings.loc[:, years.values > median_year]\n",
    "ratings_old_movies = movie_ratings.loc[:, years.values <= median_year]\n",
    "\n",
    "# Convert the rating data of old and new movies into a 1D array and remove NaN values\n",
    "new_ratings = ratings_new_movies.values.ravel()\n",
    "new_ratings = new_ratings[~np.isnan(new_ratings)]\n",
    "\n",
    "old_ratings = ratings_old_movies.values.ravel()\n",
    "old_ratings = old_ratings[~np.isnan(old_ratings)]\n",
    "\n",
    "# 1. Histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(new_movies, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Ratings for New Movies')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(old_movies, bins=20, color='red', alpha=0.7)\n",
    "plt.title('Histogram of Ratings for Old Movies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Q-Q plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "stats.probplot(new_movies, plot=plt)\n",
    "plt.title('Q-Q Plot for New Movies Ratings')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(old_movies, plot=plt)\n",
    "plt.title('Q-Q Plot for Old Movies Ratings')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b5aafed2abc23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test whether the new movie's ratings conform to the normal distribution\n",
    "stat_high, p_high = kstest(new_movies, 'norm', args=(np.mean(new_movies), np.std(new_movies)))\n",
    "if p_high > 0.005:\n",
    "    print(\"New movies' ratings appear to be normally distributed according to KS test.\")\n",
    "else:\n",
    "    print(\"New movies' ratings do not appear to be normally distributed according to KS test.\")\n",
    "\n",
    "# Test whether the ratings of old movies conform to the normal distribution\n",
    "stat_low, p_low = kstest(old_movies, 'norm', args=(np.mean(old_movies), np.std(old_movies)))\n",
    "if p_low > 0.005:\n",
    "    print(\"Old movies' ratings appear to be normally distributed according to KS test.\")\n",
    "else:\n",
    "    print(\"Old movies' ratings do not appear to be normally distributed according to KS test.\")\n",
    "\n",
    "print(\"KS test p-value for high popularity movies: \", p_high)\n",
    "print(\"KS test p-value for low popularity movies: \", p_low)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b72e8d5382818a0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Variance calculation\n",
    "variance_new = np.var(new_movies, ddof=1)\n",
    "variance_old = np.var(old_movies, ddof=1)\n",
    "\n",
    "print(\"New movies' ratings sample variance:\", variance_new)\n",
    "print(\"Old movies' ratings sample variance:\", variance_old)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b8ce9eebf41aa4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Measure skewness\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Calculate the skewness of old and new movies\n",
    "skew_new_movies = skew(new_movies)\n",
    "skew_old_movies = skew(old_movies)\n",
    "\n",
    "print(f\"Skewness for newer movies ratings: {skew_new_movies}\")\n",
    "print(f\"Skewness for older movies ratings: {skew_old_movies}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79f7c18e623d2be2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# t-test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Down sampling t-test\n",
    "num_iterations = 100000\n",
    "p_values = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    sampled_old_movies = np.random.choice(old_movies, size=len(new_movies), replace=False)\n",
    "    t_stat, p = ttest_ind(new_movies, sampled_old_movies, equal_var=True)\n",
    "    p_values.append(p)\n",
    "\n",
    "# Calculate the average of p-values\n",
    "avg_p = np.mean(p_values)\n",
    "print(f\"Average P-value after {num_iterations} iterations: {avg_p}\")\n",
    "\n",
    "# Determine significance\n",
    "if avg_p < 0.005:\n",
    "    print(\"There is a significant difference in ratings between newer and randomly sampled older movies.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in ratings between newer and randomly sampled older movies.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35f2b7083f3f6435"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform a down sampling Mann-Whitney U test\n",
    "num_iterations = 100000\n",
    "p_values = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    sampled_old_movies = np.random.choice(old_movies, size=len(new_movies), replace=False)\n",
    "    _, p = mannwhitneyu(new_movies, sampled_old_movies, alternative='two-sided')\n",
    "    p_values.append(p)\n",
    "\n",
    "# Calculate the average of p-values\n",
    "avg_p = np.mean(p_values)\n",
    "print(f\"Average P-value after {num_iterations} iterations: {avg_p}\")\n",
    "\n",
    "# Determine significance\n",
    "if avg_p < 0.005:\n",
    "    print(\"There is a significant difference in ratings between newer and randomly sampled older movies.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in ratings between newer and randomly sampled older movies.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ab38476eb7da08f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e366c8d69d02720"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preliminary analysis of the third question\n",
    "# Count the number of values 1 in column C475\n",
    "count_1 = (data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 1).sum()\n",
    "\n",
    "# Count the number of values 2 in column C475\n",
    "count_2 = (data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 2).sum()\n",
    "\n",
    "print(f'In column C475, there are {count_1} of data with a value of 1, and {count_2} of data with a value of 2.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19fec2dab59a1f78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) Is enjoyment of ‘Shrek (2001)’ gendered, i.e. do male and female viewers rate it differently?\n",
    "# Delete rows with null values for gender\n",
    "filtered_data = data.dropna(subset=['Gender identity (1 = female; 2 = male; 3 = self-described)', 'Shrek (2001)'])\n",
    "\n",
    "# Extract the ratings of Shrek (2001)\n",
    "shrek_ratings = filtered_data['Shrek (2001)']\n",
    "\n",
    "# Divide ratings based on gender\n",
    "male_ratings = shrek_ratings[filtered_data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 2]\n",
    "female_ratings = shrek_ratings[filtered_data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 1]\n",
    "print(f\"male: {len(male_ratings)},female:{len(female_ratings)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae172344483d5a14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normality graphical analysis\n",
    "# Histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(male_ratings, bins=20, alpha=0.5, label='Male')\n",
    "plt.hist(female_ratings, bins=20, alpha=0.5, label='Female')\n",
    "plt.title('Histogram of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Q-Q plot\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(male_ratings, dist=\"norm\", plot=plt, rvalue=True)\n",
    "stats.probplot(female_ratings, dist=\"norm\", plot=plt, rvalue=True)\n",
    "plt.title('Q-Q Plot of Ratings')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Ordered Values')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ce9d5dcbb5e5ed5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. Kolmogorov-Smirnov test\n",
    "male_stat, male_p = stats.kstest(male_ratings, 'norm', args=(np.mean(male_ratings), np.std(male_ratings)))\n",
    "female_stat, female_p = stats.kstest(female_ratings, 'norm', args=(np.mean(female_ratings), np.std(female_ratings)))\n",
    "\n",
    "print(f\"Kolmogorov-Smirnov Test for Male Ratings: Statistic:{male_stat}, p-value:{male_p}\")\n",
    "print(f\"Kolmogorov-Smirnov Test for Female Ratings: Statistic:{female_stat}, p-value:{female_p}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70bfd395f2ee3512"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Down sampling and perform Mann-whitney U test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "iterations = 100000\n",
    "p_values = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # 下采样\n",
    "    sampled_female_ratings = filtered_data[\n",
    "        filtered_data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 1].sample(n=241)\n",
    "    male_ratings_data = filtered_data[filtered_data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 2]\n",
    "\n",
    "    male_ratings = male_ratings_data['Shrek (2001)']\n",
    "    female_ratings = sampled_female_ratings['Shrek (2001)']\n",
    "    # Mann-Whitney U检验\n",
    "    _, p = mannwhitneyu(male_ratings, female_ratings, alternative='two-sided')\n",
    "    p_values.append(p)\n",
    "\n",
    "# 计算平均p值\n",
    "average_p_value = np.mean(p_values)\n",
    "\n",
    "print(f\"Average p-value after {iterations} iterations: {average_p_value}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "778536bdd8520605"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a87822899402aefd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 43\u001B[0m\n\u001B[0;32m     41\u001B[0m             _, p_value \u001B[38;5;241m=\u001B[39m stats\u001B[38;5;241m.\u001B[39mttest_ind(sampled_male_ratings, female_ratings, equal_var\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 43\u001B[0m             _, p_value \u001B[38;5;241m=\u001B[39m \u001B[43mstats\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mttest_ind\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmale_ratings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampled_female_ratings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mequal_var\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m         p_values\u001B[38;5;241m.\u001B[39mappend(p_value)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;66;03m# If the data does not conform to the normal distribution, use the Mann-Whitney U test\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\scientificProject\\lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:476\u001B[0m, in \u001B[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    474\u001B[0m     samples \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39masarray(sample\u001B[38;5;241m.\u001B[39mravel()) \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m samples]\n\u001B[0;32m    475\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 476\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[43m_broadcast_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    477\u001B[0m     axis \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39matleast_1d(axis)\n\u001B[0;32m    478\u001B[0m     n_axes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(axis)\n",
      "File \u001B[1;32m~\\.conda\\envs\\scientificProject\\lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:18\u001B[0m, in \u001B[0;36m_broadcast_arrays\u001B[1;34m(arrays, axis)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_broadcast_arrays\u001B[39m(arrays, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     15\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m    Broadcast shapes of arrays, ignoring incompatibility of specified axes\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m     new_shapes \u001B[38;5;241m=\u001B[39m \u001B[43m_broadcast_array_shapes\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     20\u001B[0m         new_shapes \u001B[38;5;241m=\u001B[39m [new_shapes]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(arrays)\n",
      "File \u001B[1;32m~\\.conda\\envs\\scientificProject\\lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:30\u001B[0m, in \u001B[0;36m_broadcast_array_shapes\u001B[1;34m(arrays, axis)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03mBroadcast shapes of arrays, ignoring incompatibility of specified axes\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     29\u001B[0m shapes \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39masarray(arr)\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[1;32m---> 30\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_broadcast_shapes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\scientificProject\\lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:80\u001B[0m, in \u001B[0;36m_broadcast_shapes\u001B[1;34m(shapes, axis)\u001B[0m\n\u001B[0;32m     75\u001B[0m new_shape \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m new_shapes\u001B[38;5;241m.\u001B[39mall(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;66;03m# Among all arrays, there can only be one unique non-1 shape element.\u001B[39;00m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# Therefore, if any non-1 shape element does not match what we found\u001B[39;00m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# above, the arrays must not be broadcastable after all.\u001B[39;00m\n\u001B[1;32m---> 80\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43many\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m~\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_shapes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m|\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_shapes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnew_shape\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArray shapes are incompatible for broadcasting.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# Add back the shape elements that were ignored\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\scientificProject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2317\u001B[0m, in \u001B[0;36m_any_dispatcher\u001B[1;34m(a, axis, out, keepdims, where)\u001B[0m\n\u001B[0;32m   2311\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[0;32m   2313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapreduction(a, np\u001B[38;5;241m.\u001B[39madd, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m, axis, dtype, out, keepdims\u001B[38;5;241m=\u001B[39mkeepdims,\n\u001B[0;32m   2314\u001B[0m                           initial\u001B[38;5;241m=\u001B[39minitial, where\u001B[38;5;241m=\u001B[39mwhere)\n\u001B[1;32m-> 2317\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_any_dispatcher\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   2318\u001B[0m                     where\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n\u001B[0;32m   2319\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, where, out)\n\u001B[0;32m   2322\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_any_dispatcher)\n\u001B[0;32m   2323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21many\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 4) What proportion of movies are rated differently by male and female viewers?\n",
    "# CAUTION: running this cell with 10000 iterations will take you approximate 25 minutes\n",
    "import random\n",
    "\n",
    "alpha = 0.005\n",
    "\n",
    "movies = list(data.columns)[0:400]\n",
    "\n",
    "# Variable for counting\n",
    "has_diff_counter = 0\n",
    "no_diff_counter = 0\n",
    "detailed_results = {}\n",
    "\n",
    "# Analyze each movie\n",
    "for movie in movies:\n",
    "    filtered_data = data.dropna(subset=['Gender identity (1 = female; 2 = male; 3 = self-described)', movie])\n",
    "\n",
    "    # Extract the rating of the movie\n",
    "    ratings = filtered_data[movie]\n",
    "\n",
    "    # Divide ratings based on gender\n",
    "    male_ratings = ratings[filtered_data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 2]\n",
    "    female_ratings = ratings[filtered_data['Gender identity (1 = female; 2 = male; 3 = self-described)'] == 1]\n",
    "\n",
    "    # 2. Kolmogorov-Smirnov test\n",
    "    male_stat, male_p = stats.kstest(male_ratings, 'norm', args=(np.mean(male_ratings), np.std(male_ratings)))\n",
    "    female_stat, female_p = stats.kstest(female_ratings, 'norm', args=(np.mean(female_ratings), np.std(female_ratings)))\n",
    "\n",
    "    # Make sure the two sets of samples are equal in size\n",
    "    if len(male_ratings) > len(female_ratings):\n",
    "        sampled_male_ratings = random.sample(list(male_ratings), len(female_ratings))\n",
    "    else:\n",
    "        sampled_female_ratings = random.sample(list(female_ratings), len(male_ratings))\n",
    "\n",
    "    # 3. Select the inspection method and perform inspection\n",
    "    p_values = []\n",
    "    if male_p > alpha and female_p > alpha:\n",
    "        # If both sets of data conform to normal distribution, use t test\n",
    "        for _ in range(10000):\n",
    "            if len(male_ratings) > len(female_ratings):\n",
    "                _, p_value = stats.ttest_ind(sampled_male_ratings, female_ratings, equal_var=False)\n",
    "            else:\n",
    "                _, p_value = stats.ttest_ind(male_ratings, sampled_female_ratings, equal_var=False)\n",
    "            p_values.append(p_value)\n",
    "    else:\n",
    "        # If the data does not conform to the normal distribution, use the Mann-Whitney U test\n",
    "        for _ in range(10000):\n",
    "            if len(male_ratings) > len(female_ratings):\n",
    "                _, p_value = stats.mannwhitneyu(sampled_male_ratings, female_ratings, alternative='two-sided')\n",
    "            else:\n",
    "                _, p_value = stats.mannwhitneyu(male_ratings, sampled_female_ratings, alternative='two-sided')\n",
    "            p_values.append(p_value)\n",
    "\n",
    "    # Calculate the average p-value\n",
    "    average_p_value = np.mean(p_values)\n",
    "\n",
    "    # Determine whether there is a significant difference\n",
    "    if average_p_value < alpha:\n",
    "        has_diff_counter += 1\n",
    "        detailed_results[movie] = 'Significant Difference'\n",
    "    else:\n",
    "        no_diff_counter += 1\n",
    "        detailed_results[movie] = 'No Significant Difference'\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Movies with significant gender differences in ratings: {has_diff_counter}\")\n",
    "print(f\"Movies without significant gender differences in ratings: {no_diff_counter}\")\n",
    "print(\"Detailed results:\")\n",
    "for movie, result in detailed_results.items():\n",
    "    print(f\"{movie}: {result}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T05:47:48.158011900Z",
     "start_time": "2023-10-29T05:47:44.561709200Z"
    }
   },
   "id": "4d7dd67627f10360"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:08:19.224633100Z",
     "start_time": "2023-10-29T01:08:19.209633Z"
    }
   },
   "id": "2f2d37c6dea93515"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
